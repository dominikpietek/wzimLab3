# ğŸ§  Gra Detektywistyczna â€” API z LLM NPC

## âš™ï¸ 1. Wymagania i konfiguracja Ollama

Projekt wymaga zainstalowanego Ollama oraz modelu **gpt-oss:20b**.

### ğŸ”¹ Instalacja Ollama:
Pobierz i zainstaluj Ollama zgodnie z instrukcjami: https://ollama.com

### ğŸ”¹ Pobranie modelu GPT:
```bash
ollama pull gpt-oss:20b
```

### ğŸ”§ StwÃ³rz model gry:
Projekt wymaga specjalnie przygotowanego modelu, ktÃ³ry zawiera systemowe instrukcje uÅ¼ywane przez NPC.  
Definicja modelu znajduje siÄ™ w pliku **`Modelfile`** w katalogu gÅ‚Ã³wnym projektu.
```bash
ollama create game-npc-model -f Modelfile
```

### ğŸ”¹ Uruchomienie serwera Ollama:
Przed uruchomieniem aplikacji FastAPI, naleÅ¼y oddzielnie uruchomiÄ‡ serwer Ollama:
```bash
ollama serve
```
Upewnij siÄ™, Å¼e serwer dziaÅ‚a pod adresem domyÅ›lnym `http://127.0.0.1:11434`.

### âœ… Weryfikacja:
Upewnij siÄ™, Å¼e serwer Ollama dziaÅ‚a poprawnie:
```bash
ollama list
```
PowinieneÅ› zobaczyÄ‡ na liÅ›cie model `game-npc-model:latest`.

---

## ğŸš€ Instalacja i Uruchomienie

### 1ï¸âƒ£ Zainstaluj zaleÅ¼noÅ›ci:
```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Uruchom serwer FastAPI:
UÅ¼yj przygotowanego skryptu:
```bash
python runApp.py
```

Serwer uruchomi siÄ™ pod adresem:  
ğŸ‘‰ `http://127.0.0.1:8000`

Interaktywna dokumentacja API (Swagger UI):  
ğŸŒ `http://127.0.0.1:8000/docs`

---

## ğŸ“œ Punkty KoÅ„cowe API

| Endpoint       | Metoda | Opis                                                       |
|----------------|--------|------------------------------------------------------------|
| `/npc/chat`    | POST   | Generuje odpowiedÅº od NPC (mowa, akcja, intencja).         |
| `/scene/load`  | POST   | Generuje nowÄ… scenÄ™ (opis, NPC, przedmioty).               |
| `/health`      | GET    | Sprawdza stan serwera. |